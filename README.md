# CAIPO Backend - v0.1 Prototype

[![Python Version](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Framework](https://img.shields.io/badge/FastAPI-0.115.6-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

This repository contains the backend server for the CAIPO (Capture and AI Processed Output) prototype. It's a robust and scalable service for handling media uploads, processing them asynchronously, and serving the results.

> **Sprint Goal:** End-to-end: ESP32 (or sim) â†’ audio/video â†’ backend â†’ batch Whisper transcript â†’ embeddings search â†’ tiny viewer. Quickstart â‰¤15 min.

## âœ¨ Key Features

*   **Asynchronous Processing:** Heavy tasks like AI transcription are run as background jobs, ensuring fast API response times (â‰¤100ms) and preventing HTTP timeouts.
*   **Audio & Video Ingestion:** Endpoints to upload both audio and video files. Video files automatically have their audio extracted for processing.
*   **Job Status Tracking:** A dedicated `/status` endpoint allows clients to poll for the status of a processing job (`processing`, `completed`, `failed`).
*   **AI Integration:** A service-oriented architecture integrates OpenAI's Whisper for high-quality transcription.
*   **Observability:** Built-in middleware logs every request with a unique ID and processing latency for easy debugging.
*   **Automatic Docs:** Interactive API documentation (Swagger UI) is available out-of-the-box for easy testing and exploration.

## ğŸ› ï¸ Technology Stack

*   **Framework:** [FastAPI](https://fastapi.tiangolo.com/)
*   **Server:** [Uvicorn](https://www.uvicorn.org/)
*   **Database:** [SQLModel](https://sqlmodel.tiangolo.com/) on [SQLite](https://www.sqlite.org/index.html)
*   **AI Model:** [OpenAI Whisper](https://github.com/openai/whisper)
*   **Media Processing:** [FFmpeg](https://ffmpeg.org/) (via `ffmpeg-python`)

## ğŸ“‚ Project Structure

The project follows a professional structure that emphasizes separation of concerns.

```text
caipo_backend/
â”œâ”€â”€ app/                      # All our main application code lives here
â”‚   â”œâ”€â”€ api/                  # API-specific code (endpoints/routers)
â”‚   â”‚   â””â”€â”€ v1/               # Good practice to version your API
â”‚   â”‚       â”œâ”€â”€ endpoints/
â”‚   â”‚       â”‚   â”œâ”€â”€ health.py # For the /healthz endpoint
â”‚   â”‚       â”‚   â”œâ”€â”€ status.py   # Handles polling for job status and results
â”‚   â”‚       â”‚   â””â”€â”€ upload.py # For /upload/audio and /upload/video
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ api.py        # Gathers all v1 routers
â”‚   â”œâ”€â”€ core/                 # Core logic, config, logging
â”‚   â”‚   â”œâ”€â”€ config.py         # Manages environment variables
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ db/                   # Database interaction logic
â”‚   â”‚   â”œâ”€â”€ database.py       # DB Session and engine setup
â”‚   â”‚   â””â”€â”€ models.py         # SQLModel database table models
â”‚   â”œâ”€â”€ models/               # Pydantic models for request/response validation
â”‚   â”‚   â”œâ”€â”€ media.py          # Schemas for media file uploads
â”‚   â”‚   â”œâ”€â”€ status.py         # Pydantic schemas for the status response
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ services/             # Business logic layer
â”‚   â”‚   â”œâ”€â”€ transcription.py  # Logic for calling Whisper
â”‚   â”‚   â”œâ”€â”€ video_processing.py # Logic for extracting audio from video
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py               # Main application entrypoint
â”œâ”€â”€ data/                     # Where your uploaded files will be stored
â”‚   â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ transcripts/
â”‚   â””â”€â”€ video/
â”œâ”€â”€ tests/                    # Future tests will go here
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .env                      # Environment variables 
â”œâ”€â”€ .gitignore                # To ignore files like .env, data/, __pycache__/
â”œâ”€â”€ LICENSE                
â”œâ”€â”€ README.md
â”œâ”€â”€ caipo_prototype.db        # The SQLite database file
â””â”€â”€ requirements.txt          # List of project dependencies
```

## ğŸš€ Getting Started

Follow these instructions to get the project running on your local machine.

### 1. Prerequisites

*   Python 3.9+
*   `git`
*   **FFmpeg:** This is a system-level dependency required for video processing. You must install it and ensure it's available in your system's PATH. Download it from [ffmpeg.org](https://ffmpeg.org/download.html).

### 2. Clone the Repository

```bash
git clone <your-repo-url>
cd caipo_backend
```

### 3. Set Up a Virtual Environment

**On macOS / Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**On Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

### 4. Install Dependencies

```bash
pip install -r requirements.txt
```

### 5. Configure Environment Variables

Create a `.env` file in the project root by copying the example file. The defaults are sufficient to run the application.

```bash
cp .env.example .env
```

### 6. Run the Application

Start the development server. The server will create the `caipo_prototype.db` file on its first run.

```bash
uvicorn app.main:app --reload
```
The server will be running at `http://127.0.0.1:8000`.

## ğŸ“ API Usage and Workflow

The API uses an asynchronous workflow for all media processing.

**Workflow:**
1.  **`POST`** a media file to an `/upload` endpoint. The server responds immediately with a `file_id`.
2.  **`GET`** the `/status/{file_id}` endpoint to check the progress of the job.
3.  Once the status is `completed`, the response will contain the full transcript.

### Interactive API Docs (Recommended)

The easiest way to test is using the auto-generated Swagger UI. Navigate to **`http://127.0.0.1:8000/docs`** in your browser.

### `curl` Examples

#### 1. Upload a Media File

This example uploads an audio file. The process for video is identical, just use the `/upload/video` endpoint.

```bash
curl -X POST -F "file=@/path/to/your/audio.mp3" http://127.0.0.1:8000/api/v1/upload/audio
```

**Expected Immediate Response:**
```json
{
  "status": "success",
  "file_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "filename": "audio.mp3"
}
```
**Save the `file_id` from the response.**

#### 2. Check Job Status

Use the `file_id` you received to poll the status endpoint.

```bash
curl http://127.0.0.1:8000/api/v1/status/a1b2c3d4-e5f6-7890-abcd-ef1234567890
```

**Response while processing:**
```json
{
  "file_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "status": "processing",
  "message": "File is currently being processed.",
  "transcript_text": null,
  "segments": null
}
```

**Response when completed:**
```json
{
  "file_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "status": "completed",
  "message": "Processing completed successfully.",
  "transcript_text": "The quick brown fox jumps over the lazy dog.",
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 4.1,
      "text": " The quick brown fox jumps over the lazy dog."
    }
  ]
}
```

#### 3. Health Check

Verify that the service is running.

```bash
curl -X GET http://127.0.0.1:8000/api/v1/healthz
```
**Expected Response:** `{"status": "ok"}`

## âœ… Verifying Database Operations

Since the API uses background processing, the database is the "single source of truth" for the status of any job. Hereâ€™s how you can directly inspect the SQLite database to verify that data is being saved and updated correctly. This is the definitive way to confirm the acceptance criteria: `file exists on disk + DB row`.

**Prerequisite:** The `sqlite3` command-line tool. This is typically included with standard Python installations.

### Step-by-Step Guide

1.  **Navigate to the Project Root**

    Make sure your terminal is in the `caipo_backend/` directory, where the `caipo_prototype.db` file is located.

2.  **Open the Database File**

    Run the following command to start the SQLite interactive shell and open the database file:
    ```bash
    sqlite3 caipo_prototype.db
    ```
    Your command prompt will change to `sqlite>`.

3.  **Format the Output (Recommended)**

    To make the query results readable, run these two commands inside the SQLite shell:
    ```sqlite
    .headers on
    .mode column
    ```

4.  **Query the Data**

    Now, you can run SQL queries. To see the most important fields for all the files you've uploaded, run:
    ```sqlite
    SELECT id, file_id, filename, status, transcript_path FROM mediafile;
    ```
    or to show all columns of table,
    run:
    ```sqlite
    SELECT * FROM mediafile;
    ```    
5.  **Analyze the Results**

    **Immediately after uploading a new file**, the output will show the record in its initial `uploaded` or `processing` state:
    ```
    id  file_id                               filename   status      transcript_path
    --  ------------------------------------  ---------  ----------  ---------------
    1   a1b2c3d4-e5f6-7890-abcd-ef1234567890  audio.wav  processing
    ```

    **After the background job is complete**, run the same `SELECT` command again. You will see the record has been updated. Notice the `status` is now `completed` and the `transcript_path` is filled in:
    ```
    id  file_id                               filename   status     transcript_path
    --  ------------------------------------  ---------  ---------  -------------------------------------------
    1   a1b2c3d4-e5f6-7890-abcd-ef1234567890  audio.wav  completed  data/transcripts/a1b2c3d4-....json
    ```

6.  **Exit the SQLite Shell**

    When you are finished, you can exit the tool by typing:
    ```sqlite
    .exit
    ```

This direct inspection is the fastest way to confirm your acceptance criteria and debug any issues with data persistence or background job updates.